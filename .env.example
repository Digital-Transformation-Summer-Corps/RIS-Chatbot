EMBED_BASE_URL=https://api.deepinfra.com/v1/openai
LLM_BASE_URL=https://api.mistral.ai/v1
# EMBED_BASE_URL=http://localhost:8001/v1
# LLM_BASE_URL=http://localhost:8000/v1

# Model names

EMBED_MODEL=Qwen/Qwen3-Embedding-8B
# LLM_MODEL=mistral-small-3.2-24b
# LLM_MODEL=qwen3-32b
LLM_MODEL=mistral-small-2506

# Collection settings
COLLECTION_NAME=rag_collection
PERSIST_DIR=./chroma_db

# Chunking settings
CHUNK_SIZE=8192
CHUNK_OVERLAP=512

# Query settings
SIMILARITY_TOP_K=5
QUERY_CACHE_TTL=1800

# System prompt for the AI assistant
SYSTEM_PROMPT="Answer the user question directly, with ample details so that the user does not need to look up the supplied reference. Use the information from the provided documents to answer the questions. You can add some descriptions or context to help the user understand the answer, but make sure that the answer is factually correct. Do not make statements that you are unsure about."

# API Configurations
OPENAI_API_KEY=
GEMINI_API_KEY=
DEEPINFRA_API_KEY=
MISTRAL_API_KEY=

# Validation Questions File Path
VALIDATION_QUESTIONS_FILE=document_questions_gemini.csv

# Documentation Path
DATA_DIR='RIS User Documentation/'

# Prompt Template for LLM-based validation
VALIDATION_PROMPT_TEMPLATE_FILE=validation_prompt.txt