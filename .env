# RAG Chatbot Configuration
# Copy this to .env and update with your settings

# Server URLs
# EMBED_BASE_URL=https://api.mistral.ai/v1
# LLM_BASE_URL=https://api.mistral.ai/v1
EMBED_BASE_URL=http://localhost:8001/v1
LLM_BASE_URL=http://localhost:8000/v1

# Model names
# EMBED_MODEL=mistral-embed
# LLM_MODEL=mistral-small-latest
EMBED_MODEL=nomic-embed-text-v1.5
LLM_MODEL=mistral-small-3.2-24b

# Collection settings
COLLECTION_NAME=rag_collection
PERSIST_DIR=./chroma_db

# Chunking settings
CHUNK_SIZE=4096
CHUNK_OVERLAP=512

# Query settings
SIMILARITY_TOP_K=5
QUERY_CACHE_TTL=1800

# System prompt for the AI assistant
SYSTEM_PROMPT="Answer the user question directly, with ample details so that the user does not need to look up the supplied reference. Use the information from the provided documents to answer the questions. You can add some descriptions or context to help the user understand the answer, but make sure that the answer is factually correct. Do not make statements that you are unsure about."

# Gemini API Configuration
GEMINI_API_KEY=AIzaSyBPjC8GEDYljn3_E53uoOBVZKmGMrpIbrI

# Validation Questions File Path
VALIDATION_QUESTIONS_FILE=document_questions_o3.csv

# Documentation Path
DATA_DIR='RIS User Documentation/'

# Prompt Template for LLM-based validation
VALIDATION_PROMPT_TEMPLATE_FILE=validation_prompt.txt